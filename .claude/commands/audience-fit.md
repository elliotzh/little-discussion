评估文档各部分内容与目标受众的匹配度——受众对每部分的关心程度和理解难度。

## 准备工作

1. 确定目标文档：使用 `$ARGUMENTS` 指定的路径。如果未指定，自动查找 `docs/` 目录下最近修改的 `.md` 文件。
2. 读取文档同目录下的 `meta.json`，提取目标文档的 `target_audience`（受众身份）、`usage`（使用场景）和 `tone`（语气要求）。如果 `meta.json` 不存在或未定义 `target_audience`，告知用户此命令需要受众信息才能运行，并结束。
3. 读取文档全文。

## 受众画像构建

基于 `meta.json` 中的受众信息，先输出一段简要的受众画像（3-5 句），明确：

- **身份与职责**：受众是谁，日常关注什么
- **知识背景**：对 AI/技术的了解程度，对行业术语的熟悉度
- **阅读动机**：为什么会读到这份文档，期望从中获得什么
- **决策权限**：能做什么决定，关心什么层面的信息（战略/执行/技术）

## 逐节评估

对文档的每个章节（以二级标题 `##` 为单位，三级标题 `###` 作为子项分别评估），输出以下评估：

### 评估维度

**关心程度**（受众对该内容的在意程度）：
- 🔴 **核心关切**：直接影响受众的决策或利益，是受众阅读本文档的主要动机
- 🟡 **有所关注**：与受众的关切相关但非核心，作为背景或支撑信息有价值
- ⚪ **较少关心**：受众可能会跳过，或读完后觉得"这跟我关系不大"

**理解难度**（受众理解该内容的认知负担）：
- ✅ **容易理解**：用受众熟悉的语言和概念表达，无需额外解释
- ⚠️ **需要消化**：包含受众不常接触的概念或逻辑，但通过上下文可以理解
- ❌ **理解困难**：包含受众知识背景之外的术语、技术细节或抽象概念，可能导致困惑或失去耐心

### 输出格式

用表格呈现全局概览，然后对需要关注的章节给出详细说明：

#### 全局概览

| 章节 | 关心程度 | 理解难度 | 一句话说明 |
|------|---------|---------|-----------|
| （章节标题） | 🔴/🟡/⚪ | ✅/⚠️/❌ | （为什么是这个评级） |

#### 需要关注的匹配问题

只列出存在"失配"的章节——即以下任一情况：

1. **高关心 + 高难度**（🔴❌）：受众最在意但最难懂，是最需要优先优化的部分
2. **低关心 + 高篇幅**（⚪ + 占文档较大比重）：受众不太关心但占据大量篇幅，可能导致阅读疲劳
3. **高关心 + 低篇幅**（🔴 + 内容较少）：受众最关心的内容说得不够充分
4. **术语/概念断层**：某处突然引入受众不熟悉的概念，缺乏铺垫

对每个匹配问题，说明：
- 具体位置（行号或引用原文）
- 问题性质（上述 1-4 哪一类）
- 改进方向建议（不需要给出具体改写文本，指出方向即可）

#### 总体评价

一段话总结：文档整体对目标受众的适配程度如何，最值得优化的 1-2 个方向是什么。

## 注意事项

- 评估基于受众画像，不是基于审阅者自身的理解——一个 AI 工程师觉得简单的内容，对非技术背景的 CXO 可能理解困难
- 关心程度不等于重要性——某个章节对文档论证很重要，但受众可能并不关心（例如技术细节对决策者）
- 不要与 `/review-doc` 重复：本命令不评估论证逻辑、术语一致性、信息隔离等——只聚焦受众匹配度这一个维度
